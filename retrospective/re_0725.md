## 리뷰
  
## 오늘 한 일

### MapReduce Job 정리
- 빅 데이터가 들어와 hdfs에 저장을 했다 > 대용량 파일을 여러 개의 작은 블록 단위로 나누어 Hadoop Cluster 내의 여러 DataNode에 분산하여 저장 > 이때 각 블록은 데이터 유실 방지를 위해 여러 개의 복제본을 만들어 다른 노드에 분산 저장( 스케줄러는 복제본을 알고 있는 상태 ) > 블록들을 기반으로 입력 스플릿이 생성 > 각 입력 스플릿에 대해 하나의 Map task 할당 > DataNode에서 map task 실행 > 태스크 완료 후 그 결과인 중간 데이터를 자신이 실행된 노드의 로컬 디스크에 기록함
- 작은 블록 단위로 나누고 Split을 하는데 일반적으로 블록 사이즈와 Split하는 사이즈가 거의 비슷하다고 함. 처음에는 블록 단위로 나누는게 Split인 줄 알았다.

- Data Locality에 대해 잘 이해가 되지 않았었는데 왜 그런가 했더니 하나의 Cluster 안에 하나의 가상 머신/컴퓨터가 있다고만 생각하니 Data Local / Rack Local / Different Rack에 대해 잘못 이해하고 있었다.
- Input Data가 너무 커서 Hadoop Cluster에 여러 개의 컴퓨터가 있다고 가정했을때 Resourcemanager, NameNode는 클러스터 전체에서 하나 혹은 백업용으로 하나 더 존재함 > 같은 컴퓨터든 다른 컴퓨터든 네트워크 통신으로 SlaveNode/WorkerNode를 관리함( 컴포넌트가 자기 위치를 인식하지 않아도 됨 그냥 네트워크로 통신하는걸로 통일함 )
- 이렇게 생각을 하니까 Data Local / Rack Local에 대해서도 이해하기 쉬웠음 / Different Rack이라는 건 같은 Hadoop Cluster 내에 존재하는 자신 이외의 컴퓨터를 의미하는 것.
- MapTask, ReduceTask는 모든 WorkerNode에 있지않음. 만약 자기 workerNode에 MapTask가 없다면 다른 노드의 MapTask를 써야하는데 이럴때를 Rack Local 이라고 한다. MapTask를 같은 WorkerNode에서 진행할때를 Data Local이라고 한다.

### 헷갈리는 부분
- MapTask, ReducerTask를 하면서 sort가 언제 일어나는지, sort&shuffle라고 묶여 있는 이유에 대해 의문점이 생겼다.
  - MapReduce Job에서 Shuffle은 Map 단계가 완료된 후, Reduce 단계가 시작되기 직전에 발생 - Shuffle 단계는 Hadoop MapReduce 프레임워크(Yarn)에 의해 자동으로 관리, 직접 코드로 구현할 필요가 없음
 
### Shuffle을 방지하는 방법
1. Map-Only Job
   - Reducer가 없게 만들어 MapTask의 출력이 바로 hdfs에 저장되게 만듬
   - grep과 같이 단순히 데이터를 찾거나 변형만 하고 집계가 필요 없는 경우 사용함 >> 단어별 총 개수는 얻을 수 없음
  
2. Combiner (셔플되는 데이터 양 최소화)
   - 셔플을 완전히 방지하는 것은 아니지만, 셔플되는 데이터의 양을 크게 줄여 네트워크 I/O를 최소화하는 효과적인 방법
   - MapTask가 실행되는 노드의 로컬에서 중간 결과를 부분적으로 집계하는 "미니 리듀서"
   - key-value를 네트워크를 통해 리듀서로 보내기 전에, 같은 키를 가진 값들을 로컬에서 미리 합쳐서 보냄
   - Hadoop streaming에 -combiner 옵션을 추가해야됨 (reducer.py 스크립트를 그대로 사용해도됨)
   - Combiner는 MapTask A,B,C의 결과를 합치는게 아니라 각각의 MapTask의 결과를 따로 집계하는 방식 > MapTask A에서 같은 Key값이 여러 번 나올 때 그 안에서 중간 집계함


- 똑같은 지피티에 팀원이랑 같은 질문을 했는데 대답이 서로 달랐다. MapTask에서 sort가 일어난다는 답변과 ReduceTask에서 sort가 일어난다는 답변이 있어 제대로 알아볼 예정이다.

### W3M2 팀 활동 요구사항
- **core-site.xml**
  - Change fs.defaultFS to hdfs://namenode:9000. 가장 중요하다고 생각
  - 이 항목은 Hadoop 클러스터 전체의 기본 파일 시스템을 정의하기 때문에, 나머지 설정들이 아무리 올바르게 되어 있어도 이 설정이 잘못되면 클러스터 자체가 동작 불능 상태가 됨.
  - HDFS를 제대로 활용하기 위해선 hdfs://namenode:9000처럼 정확한 주소 지정이 필수.

### W3M4 팀 활동 요구사항
- 기존에는 미리 정의된 키워드(predefined keywords)를 기반으로 텍스트를 분류했지만, 이 방식은 유연성이 떨어지고 새로운 유형의 데이터에 대응하기 어렵기 때문에 TextBlob을 활용하여 감정 분석 및 명사 추출을 통해 텍스트를 동적으로 분류하는 대안을 생각했음



## 회고
  
### Keep
- 

### Problem
- 한 주 동안 진행되는 과제를 다 못 끝냈다 > 남는 시간을 활용해서라도 꼭 끝내자.

### Try


