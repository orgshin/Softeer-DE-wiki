## 리뷰
  
## 오늘 한 일

### W3M2b
- 엄청나게 큰 Hadoop 클러스터가 존재할 때, Configuration을 수정하고 모두 Restart 해야하는 시나리오라고 가정했다. 그럴 때 미션에서 주어진 스크립트는 효용성이 크다고 생각한다.
- 하지만 내가 구축한 멀티 노드 하둡 클러스터의 프로세스들은 start-dfs.sh, start-yarn.sh를 사용해 생성하거나 SSH로 통신하지 않는다. 따라서 스크립트에 각각 NameNode, DataNodes 등등을 명시적으로 재시작하도록 지정해줘야 한다.
- 반면 미리 정의된 스크립트와 $HADOOP_HOME/etc/hadoop/workers 설정을 이용한다면 NameNode에만 operation을 지정해 전부 재시작할 수 있을 것이다.
- 결국 미션의 요구사항을 만족하는 스크립트를 작성하더라도 많이 배우지 못할 것이라 생각한다. 따라서 성격이 비슷한 W3부터 W6까지 빠르게 해결한 후, 클러스터의 구성을 수정하고 스크립트를 작성할 계획이다.

### W3M3
- MapReduce job을 정의한 스크립트를 작성한다.
- 스크립트 자체는 빠르게 구현하고 로컬에서 테스트에 성공할 수 있었다.
	1. NameNode의 컨테이너 공간에 스크립트를 복사한다.
	2. NameNode에서 Hadoop command를 실행해 ResourceManager에 작업을 등록한다.
	3. HDFS에 저장된 처리 결과를 확인한다.

### W3M4
- 
## 회고
  
### Keep
-

### Problem
-

### Try
-

