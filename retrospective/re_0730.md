## 리뷰

### W4M2 Spark 오늘 겪은 문제점
- JAVA_HOME, SPARK_HOME 환경 변수가 Jupyter notebook의 파이썬 환경에서 제대로 인식되지 않았음
- Spark가 컴파일된 Java 버전(17)과 시스템의 Java 버전(11) 불일치로 인해 계속 에러가 뜨는 문제 발생 > spark 관련 경로를 직접 설정하는 방식으로 해결
- Jupyter가 PySpark가 설치된 파이썬 환경을 제대로 인식하지 못해 모듈에러가 발생 > ipykernel을 사용해 PySpark 환경을 주피터에 커널로 등록
- 어제 요구사항대로 완료한 후 기온, 강수량만으로 택시 이용률과 관련해서 유의미한 인사이트를 도출할 수 없었기 때문에, 요일 / 공항에 대한 데이터를 추가해서 상관관계를 파악하려고 시도중

### AWS
- 인터넷에 접속하기 위한 조건
  1. pem 키
  2. Public IP 주소
  3. IGW( 인터넷 게이트웨이 )
  4. SG( 보안그룹 )

- AWS S3 : 리젼 내의 서비스지만 VPC의 서비스가 아니기 때문에 
  1. Bucket 이름( global unique )
  2. Object 저장( 버킷 내에서 unique 해야됨): 이름이 같은 파일을 다시 업로드하면 덮어씌움 > versioning을 쓰면 모든 파일을 기억 > 비용 발생
     - 모든 오브젝트를 url로 접근 가능 ( presigned가 된 url에 접근이 가능 - 일정 시간을 정해놓고 expired되게 만듬 )
     - 비용
       1. 저장된 크기
       2. 다운로드 비용
       3. 통신 비용( 같은 리전 내에서 사용시 비용 면제 )

### W4M3 팀 요구 사항 요약
- 수평적 확장성과 독립적인 노드 개념에 중점을 둠(독립적인 크롤링 노드 클러스터를 12개 사용)
- 각 노드는 다른 노드와 통신하지 않고 자체적으로 작업을 수행하며, 특정 도메인 샤드(데이터베이스를 여러 개의 작은 부분으로 나누어 저장)를 담당 > 단일 장애 지점을 줄이고, 시스템 복원력을 높임
- 인스턴스 스토리지를 사용해서 Redis 데이터를 영구 저장하는 대신, 임시로 저장해 비용을 절감함 > 인스턴스가 종료되면 데이터가 사라지지만 비용이 매우 저렴하고, 크롤링의 최종 결과물만 저장하면 되기때문에 이 방법을 선택
- asyncio 라이브러리를 사용해 네트워크 요청/파서 프로세스를 비동기적으로 처리할 수 있게 해 높은 동시성을 가짐
- 좋은 머신을 써서 수직적 확장을 하는 것보다 여러 개의 작은 머신을 사용하는 것이 대규모 크롤링에 훨씬 효과적이라는 것을 확인함 > 분산 시스템의 장점을 볼 수 있었음

1. 인상적인 내용
  - 

2. 아키텍처
  - 12개의 독립적이고 자체 포함된 노드로 구성된 클러스터, 각 노드가 특정 도메인 샤드를 담당
  - 파싱이 네트워크 I/O보다 병목 현상
  - Fetching 과정에서 비대칭키 연산, 대칭키 암호화/복호화 등으로 인해 Network-bound보다 CPU-bound가 발생 > 직접적인 해결책은 제시 x, 대규모 크롤링 시스템 설계 시 고려해야 할 중요한 성능 병목 지점으로 제시
    - 참고: 일반적인 해결책으로는 더 강력한 CPU 사용, SSL Offloading, 기존 TCP/SSL 연결을 재사용해서 매번 새로운 핸드셰이크를 수행하는 오버헤더를 줄임
  - 인스턴스 스토리지 사용, S3 같은 클라우드 스토리지를 사용하지 않아 비용 절감 > 인스턴스가 종료되면 데이터가 사라지지만 위험 감수
  - JavaScript를 실행하지 않고, 순수 HTML Parsing만으로도 많은 정보를 얻을 수 있음
  - 수직 확장을 하는 거보다 대규모 분산 시스템의 이점을 활용한 수평 확장

## 회고
  
### Keep
- 

### Problem
- 한 달로 한정해 요인을 늘려가며 상관관계를 파악하고 있는데, 기간을 늘려볼 필요가 있을 거 같음

### Try
- 
