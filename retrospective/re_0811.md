## 리뷰
### 강의
- spark를 튜닝하는게 아니라 Job을 튜닝하는것이다
- data = Job 데이터를 모르고 optimizing을 한다는건 말이 안 됨 > 오늘 배우는 optimizing은 우리가 함
- the communication between nodes : spark 구조에서 제일 bottle neck임 > 그래서 shuffle을 어떻게 줄일지 혈안이다
- parquet를 쓰면 shuffle을 줄일 수 있다?
- predicate push down
  - df.select(나이,성별).filter("age>20") >> 연산이 훨씬 크다, 비효율적인 방식
  - df.filter("age>20").select(나이,성별) >> 전체가 100만개라고 치면, 나이가 20살 이하인 90만 개의 데이터를 즉시 버리고 10만 개의 데이터에서 select
- Data Warehouse : 목적성을 갖는다
- Data Lake : 데이터를 일단 다 때려넣는다. 자주 쓰는 데이터는 structured, 로그 같은 데이터는 unstructured로 때려넣음
  - ELT가 그래서 나옴, 일단 저장해놓고 필요하면 Transform해서 씀
- Data Lakehouse : Cloud가 필요함
- network를 타는게 spark에서 제일 느린 bottle neck임
- repartitionByRange : 데이터를 보고 repartitioning 할 지를 결정해야된다. 예를 들면 서울역 일요일/ 금요일 승객이 다르니까 다르게 처리해야되듯이
- 스파크는 인메모리 툴이 아니다. LRU를 가진
- 캐시는 메모리에 들어가고, persist는 메모리나 디스크에 저장
- cache, persist, checkpoint(리니지를 갖고있는 RDD가 아니다)
- persist & checkpoint를 같이 쓰면 cache는 그 DAG안에서 두 번 세 번 쓰일때 사용, checkpoint는 다른 spark Job에서 다시 사용할 수 있으니까 같이 사용
- 결국 우리는 데이터를 보고 DAG를 개선하는 일이다.

### Optimizing Spark Job Homework

1. Execution Memory 초과 시
  - 실행 메모리는 셔플(shuffle), 조인(join), 정렬(sort), 집계(aggregation)와 같은 연산 중에 필요한 데이터를 임시로 저장하는 공간입니다.
  - 만약 실행 메모리가 부족해지면, 스파크는 디스크로 데이터를 흘려보내는(Spilling) 작업을 수행합니다. 즉, 메모리에 더 이상 저장할 공간이 없을 때 초과된 데이터를 디스크에 임시 파일로 기록하지만 성능 저하를 유발할 수 있습니다.
  - 만약 디스크 공간마저 부족해지거나 spilling으로도 감당이 안 될 경우, OutOfMemoryError가 발생하며 해당 태스크(task)는 실패하게 됩니다.
  - 결론 : 실행 메모리가 부족하면 disk spilling이 발생하여 성능이 저하됩니다.

2. Storage Memory 초과 시
  - 스토리지 메모리는 cache()나 persist()를 사용하여 RDD나 데이터프레임을 캐싱하는 데 사용되는 공간입니다.
  - persist()를 사용하지 않는다고 가정했으므로, 이 메모리 영역은 RDD의 파티션을 브로드캐스트 변수 등으로 메모리에 저장할 때 외에는 적극적으로 사용되지 않을 수 있습니다. 하지만 만약 사용 중인 스토리지 메모리가 부족해지면, 스파크는 가장 오래전에 사용된(LRU: Least Recently Used) 캐시 블록을 메모리에서 제거합니다.
  - 캐시 데이터 제거: LRU 정책에 따라 가장 오랫동안 접근되지 않은 데이터 블록부터 메모리에서 지워집니다.
  - 재연산 필요: 나중에 해당 데이터가 다시 필요하게 되면, 스파크는 원본 소스로부터 다시 읽어와 이전에 수행했던 모든 연산(transformation)을 재실행해야 합니다. 이는 상당한 연산 비용을 초래하여 성능을 저하시킵니다.
  - 만약 persist()의 저장 레벨(storage level)을 MEMORY_AND_DISK로 설정했다면, 메모리에서 제거된 블록은 디스크로 옮겨질 수 있습니다. 하지만 전제와 같이 persist()를 아예 사용하지 않는다면, 데이터는 단순히 제거되고 필요시 처음부터 다시 계산됩니다.
  - 결론 : 스토리지 메모리가 부족하면 오래된 캐시 데이터가 제거되며, 해당 데이터가 필요할 때 재연산이 발생합니다.

3. User Memory 초과 시
   - 사용자 메모리는 스파크가 직접 제어하지 않기 때문에, 이 영역이 할당된 크기를 초과하면 스파크의 메모리 관리 메커니즘(spilling, LRU eviction 등)이 작동하지 않습니다. 따라서 사용자 메모리가 부족해지면 곧바로 OutOfMemoryError가 발생하며, 이는 전체 애플리케이션의 실패로 이어질 수 있습니다.
   - 결론 : 사용자 메모리가 부족하면 별다른 대처 없이 즉시 **OutOfMemoryError**가 발생하여 애플리케이션이 중단됩니다.

### 최종 프로젝트 아이디어 구체화

- 우리의 데이터 프로덕트 사용자 여정을 짜봤습니다 ( 사용자가 견적서 평가를 보고 해당 정비소에서 수리를 받을 지 말 지 선택, 견적서 비교를 할 지 말 지도 사용자 마음이다. )
  1. 정비소 A를 들려서 견적을 내고 우리 프로덕트에 견적서를 넣어서 견적 평가를 받았음, 근데 과잉정비가 떴다 이 상황에서 다른 정비소를 추천하는 기능을 추가(거리, 리뷰데이터를 통해 가격이나 평점, 공업사 등급 등)
  
  2. 프로덕트 사용자가 정비소 B를 들렸는데 또 과잉정비가 떴음, 이럴때 1번과 같은 프로세스를 진행함
  
  3. 다음으로 정비소 C를 들렸더니 어중간한 케이스가 떴다, 이때도 다른 정비소를 똑같은 방법으로 추천해줌, 여기서 사용자는 정비소 C에서 그냥 받을지, 다른 정비소를 또 들릴지 결정. 정비소 C에서 받으면 끝인거고, 만약 다른 정비소를 가기로 결정했다고 쳤을때 4번으로 넘어감
  
  4. 정비소 D를 들렸더니 어중간한 케이스나 걱정이 사라지는 케이스가 떴어. 이때도 다른 프로세스랑 똑같이 추천 정비소는 디폴트로 추천을 해줘, 근데 사용자가 걱정이 사라지는 케이스에서 정비를 받을 수도 있는거고, 다른 견적이랑 비교를 받을 수도 있어. 이건 사용자 마음이야. 근데 만약, 이번에도 마음에 안 들어서 조금이라도 더 깍고 싶은 마음이 생겨서 다른 정비소를 들렸어. 그럼 총 5번 견적 평가를 받았으니 여기서 끝. 우리 서비스는 5만원을 내면 최대 5번 견적 평가를 받을 수 있게 제한을 걸었음 > 마음에 안 든다고 무제한으로 견적을 받게 할 순 없기 때문에.


## 회고
### Keep
- 

### Problem
- 아이디어를 구체화하는 과정에서 다노강사님의 피드백을 듣고 나니 자동차에 대한 경험이나 도메인 지식이 부족해서 잘못된 케이스에 대해 쓸 데 없는 생각을 하고 있었다. 이런 문제들을 해결하기 위해서 주변에 차에 대한 경험이 많거나 관심이 많은 사람 / 지피티, 잼민이를 잘 활용해서 부족한 지식을 채워 프로토타입과 이 이후 과정에서 올바른 생각을 할 수 있도록 노력해야겠다.

### Try
- 
