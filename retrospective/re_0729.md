## 리뷰

### Spark
- 하둡은 병렬처리를 하긴하지만 모든 연산을 disk I/O를 일으키면서 연산 하기때문에 되게 느림
- 하나의 워커 노드 당 Executor를 몇 개 가지는지 헷갈렸는데 성능과 Job에 따라 몇 개의 Executor를 사용할지 지정할 수 있고 이 Executor들은 사용 가능한 워커 노드에 분산되어 할당됨
- 요약하자면, 워커 노드는 executor를 실행하는 컨테이너 역할을 하고 일반적으로 하나의 워커 노드에서 여러 개의 executor가 동시에 실행되어 병렬 처리 능력을 극대화함
- Executor는 spark application 애플리케이션의 일부로, 워커 노드에서 실제 계산 작업을 수행하는 JVM process임

## 회고
  
### Keep
- 

### Problem
- 

### Try
- 
