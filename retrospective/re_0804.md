## 리뷰

## 강의
- MapReduce는 똑같은 데이터를 계속 iterative하게 처리함
- RDD : Overcoming Redundancy and Lack of In-Memory Reuse in MapReduce
- 하둡은 fault tolerance를 replication으로 지원, 스파크는 lineage로 지원
- 하둡은 local disk에서 깨져도 다시 하면되니까 fault tolerance가 필요 x, 스파크는 In-memory가 깨지면 안 되기 때문에 fault tolerance를 보장해줘야된다 생각함 / In-memory를 반복 사용 >> 깨지면 안 되니까 lineage 사용
- lineage : 자식이 깨지면 그 부모를 찾아가고 부모가 깨지면 조부를 찾아가고, 이런식으로 Resilient함
- immutable을 왜 썼을까? 동일한 데이터를 많은 프로세스가 쓸 때 혼란 생길게 없어서
- 파티션 사이즈를 잘 결정하는게 중요함 > 불균등하게 배분될 수 있기 때문 > 전형적으로 스파크가 알아서 정해줌
- spark context : action이 불러질때 job이 생성됨, 그 전까지는 기록만 하고있음(DAG)
- logical plan이 있으니까 physical plan을 DAG가 만들어냄?
- 하둡을 할 때는 체인 잡을 자기가 알아서 하느라 귀찮고 시간이 많이 걸렸는데, 스파크에서는 알아서 해줌
- 데이터가 있고 프로세싱이 있는거지, 프로세싱이 있고 데이터가 있을 수는 없다
  
1. Action : 굴리는 순간 실행
2. Transformation : 바로 실행되지 않음
- Action과 Transformation을 구분하는건 RDD가 생겼는지의 여부

- Lazy Evaluation은 코드를 킵 해놨다가 Action하는 순간 타고 올라가면서 숙제를 실행 / 불필요한 계산을 optimize하게 관리해줌
- Transformation의 연결선이 lineage다

1. Narrow : Shuffle을 안 일으킴
2. Wide : Shuffle을 일으킴

- Stage : Task의 집합, serially하면 같은 파티션에 놓는다, 절대 쪼개지 않음
- Computation boundaries : shuffle이 끝날때까지 reduce가 불가능함, 경계선이 존재

### 최종 프로젝트
- 현대 자동차가 신차를 출시했을때 소비자들의 반응 ( 이전 기수 주제 )
- 자동차 제조/판매/운용 또는 교통/모빌리티와 관련된 분야에서 상업적으로 사용에 문제가 없는 공개된 데이터와 온라인 상에 공개된 소비자들의 반응 데이터를 직접 수집/가공/활용해서 상업적 가치를 만들어 내는 데이터 프로덕트
  - 주제를 좁혀야된다 -> "어떤 문제 상황을 생각하고 누구의 > 어떤 문제 > 어떻게 해결"을 브레인 스토밍 방식으로 직접 쓰면서 구체화하다보면 쓸만한 아이디어인지, 폐기처분해야되는지 대충 감이 잡힐 거 같다. 이 과정에서 데이터를 구할 수 있을지에 대한 고민은 하지 말고 일단 아이디어를 내보자.

## W5M1
- Parquet 파일의 데이터를 Spark RDD로 읽어서 5가지의 Transformations를 적용해 요구사항을 만족시켰음
  1.  **`map`**: 원본 데이터(`Row` 객체)를 `(날짜, 거리, 요금)` 형태의 튜플로 변환하고, 유효하지 않은 데이터는 `None`으로 처리합니다.
  2.  **`filter`**: `map` 과정에서 `None`으로 처리된 유효하지 않은 레코드를 제거합니다.
  3.  **`map` (집계 준비)**: 일일 집계를 위해 데이터를 `(날짜, (1, 요금))` 형태의 키-값 쌍으로 변환합니다. `1`은 여행 횟수를 의미합니다.
  4.  **`reduceByKey`**: 날짜(키)를 기준으로 데이터를 그룹화하여 일일 총 여행 횟수와 총수입을 계산하는 Wide Transformation입니다.
  5.  **`mapValues`**: `reduceByKey`로 집계된 데이터에서 일일 평균 요금을 계산하는 Narrow Transformation입니다.
  6.  **`join`**: **(5가지 이상 변환 요구사항 충족)** `reduceByKey`로 계산된 일일 요약 RDD(`daily_summary_rdd`)와 `mapValues`로 계산된 일일 평균 요금 RDD(`daily_avg_fare_rdd`)를 `join`합니다. 이 Wide Transformation을 통해 최종적으로 `(날짜, ((총 여행 수, 총수입), 평균 요금))` 형태의 데이터를 생성하여, 각 날짜별 요약 정보와 평균 요금을 하나의 레코드에서 확인할 수 있도록 데이터를 만들었다.

## 회고
  
### Keep
- 

### Problem
-

### Try
- 자동차에 대한 도메인 지식이 부족하기 때문에 제대로 된 데이터 프로덕트를 만들기 위해서 일단 아이디어를 여러 개 내고, 그 아이디어에 필요한 도메인 지식을 넓혀 데이터에 대한 이해를 바탕으로 사용자의 니즈에 맞게 최종 프로젝트를 만들어야겠다.
