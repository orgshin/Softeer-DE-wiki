## 리뷰

## W4M3 팀 미션 : 대규모 웹 크롤러 분석

## 1. 가장 인상적이었던 내용

팀원들은 공통적으로 **기존 통념을 깨는 효율적인 시스템 설계**에 깊은 인상을 받았습니다.  
특히, **500달러 미만의 저비용으로 대규모 크롤링을 달성**했다는 점에 주목했습니다.

- **비용 절감 전략**  
  S3와 같은 영구 클라우드 스토리지를 포기하고, 인스턴스 종료 시 데이터가 손실될 위험을 감수하며 **인스턴스 스토리지**를 채택.

- **성능 한계 인식**  
  하드웨어·소프트웨어 발전에도 불구하고 웹 콘텐츠(JavaScript, 고용량 미디어 등)가 무거워져 성능 향상에 한계 존재.  
  그럼에도 **순수 HTML 파싱만으로도 충분히 가치 있는 데이터**가 많음을 확인.

- **노드 수 최적화**  
  크롤링 노드를 무작정 늘리지 않고, **'핫 샤드(Hot Shard)' 현상** 방지를 위해 12개 노드만 유지.  
  → 트래픽 불균형 방지와 시스템 효율 유지.

---

## 2. 아키텍처에 대한 논의

### 전체 시스템 구조
- **수평 확장에 유리한 아키텍처**  
  12개의 독립 노드로 구성된 클러스터.  
  각 노드는 **할당된 도메인 샤드만 독립 처리**하여 **내결함성(Fault-tolerance)** 확보.
- **클러스터 구성**  
  - 인스턴스: 12대 i7i.4xlarge (vCPU 16, RAM 128GB, 10Gbps 네트워크, 3750GB 인스턴스 스토리지)
  - 작업 분배: 상위 100만 도메인을 12개로 샤딩하여 균등 할당
  - 노드 간 통신 없음 → 단일 노드로도 실험·확장 가능

### 노드 내부 구조
각 노드는 **Fetcher + Parser + Redis 인스턴스**가 결합된 작은 클러스터처럼 동작.

#### Redis 인스턴스
- **Frontier**: 도메인별 URL 처리 큐
- **Ready Queue**: 크롤링 지연시간(Crawl Delay) 반영, 다음 방문 도메인 정렬
- **Bloom Filter**: Frontier 중복 삽입 방지
- **Parse Queue**: Fetcher → Parser HTML 전달
- **메타데이터**: robots.txt 정보, 크롤링 완료 URL 목록(Visited Set)

#### Fetcher 프로세스 풀
- 9개 프로세스, 프로세스당 **6,000~7,000 비동기 워커**
- Ready Queue에서 도메인 가져와 크롤링 → 결과를 Parse Queue에 전달

#### Parser 프로세스 풀
- 6개 프로세스, 프로세스당 **80 워커**
- Parse Queue에서 HTML 파싱 후 추출된 링크를 Frontier에 추가
- 파싱 결과는 **250KB 이하로 잘라 로컬 저장**

#### LRU 캐시
- Fetcher, Parser 모두 robots.txt 등 반복 참조 정보 캐싱
- Redis 접근 최소화로 성능 최적화

---

## 3. 놀라웠던 의사결정

### CPU 병목 현상 규명
- 일반적으로 웹 크롤링 병목은 네트워크 I/O라고 생각되지만,  
  이 시스템에서는 **Fetcher(암·복호화)**와 **Parser(HTML 파싱)** 모두 **CPU-bound**임을 확인.

### 비대칭 워커 수 설정
- **Fetcher**: CPU 부담 있음에도 수많은 연결을 처리해야 하므로 **6,000~7,000 비동기 워커**
- **Parser**: 순수 CPU 연산이라 워커를 늘리면 컨텍스트 스위칭 오버헤드 증가 → **80 워커로 제한**

### 중복 URL 사전 차단
- Visited Set 외에도 Frontier 단계에서 **Bloom Filter**로 중복 URL 차단
- 파이프라인에 불필요한 데이터 진입 방지 → 효율 극대화


   
## 회고
  
### Keep
- 

### Problem
- 

### Try
- 
