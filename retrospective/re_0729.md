## 리뷰

### Spark
- 하둡은 병렬처리를 하긴하지만 모든 연산을 disk I/O를 일으키면서 연산 하기때문에 되게 느림
- 하나의 워커 노드 당 Executor를 몇 개 가지는지 헷갈렸는데 성능과 Job에 따라 몇 개의 Executor를 사용할지 지정할 수 있고 이 Executor들은 사용 가능한 워커 노드에 분산되어 할당됨
- 요약하자면, 워커 노드는 executor를 실행하는 컨테이너 역할을 하고 일반적으로 하나의 워커 노드에서 여러 개의 executor가 동시에 실행되어 병렬 처리 능력을 극대화함
- Executor는 spark application 애플리케이션의 일부로, 워커 노드에서 실제 계산 작업을 수행하는 JVM process임

### AWS
- api 호출 ( 앞 단에 IAM이 존재 -> 너 누군데, 권한 있음? )
  1. console
  2. CLI AWS
  3. AWS SDK
- Role ( 사용하는 두 개의 케이스 / 유저 or AWS 리소스 )
  1. 정책을 덮어 씌운다.
  2. 롤에 정책을 주지 않은채로 유저에게 롤을 씌우면 기존에 사용할 수 있던 정책이 날아가고 아무 정책을 사용할 수 없음 ( 유저 한정 )
  3. AWS 리소스 (대표적으로 EC2, lambda)는 다른 AWS
- AWS Global infra
  1. Region : AWS 서비스 도시 이름
     - Availability zone(A.Z/가용영역) - 하나의 리젼에는 보통 두 개 이상의 A.Z가 존재 != 데이터 센터 / 하나의 AZ 안에 여러개의 데이터 센터가 존재할 수 있음
  2. Edge location : 빠른 응답이 필요할때 사용 ( DNS, CDN )
- VPC
  1. 서브넷을 고를때는 서로 다른 가용영역에 있는 서브넷을 골라야 하나가 죽었을때 하나가 남음
 
### W4M2

1. 택시 데이터 전처리 및 집계
    - 원본 택시 데이터(tpep_pickup_datetime)에서 필요한 날짜와 시간 추출해서 pickup_date, pickup_hour 컬럼을 생성
    - 지역(Borough) 정보 추가 → 택시 데이터의 PULocationID를 Taxi_zones의 LocationID랑 매치를 해서 left join을 수행해 택시 데이터에 Borough(자치구) 컬럼을 추가해서 새로운 DataFrame 생성
    - 새로운 데이터프레임(df_taxi_with_borough)를 borough, pickup_date, pickup_hour 세 가지 컬럼을 기준으로 그룹화
    - agg(count("*").alias("trip_count"))를 사용하여 각 그룹(즉, 특정 지역의 특정 날짜/시간)에 해당하는 택시 이용 횟소를 세어 trip_count라는 새 컬럼을 만듬 - trips_by_borough_date_hour
    - 새로 만든 데이터프레임은 각 지역의 특정 날짜/시간(예, 맨해튼, 2025-05-31, 13시)에 대한 총 택시 이용 횟수를 가지고 있음
    
2. 날씨 데이터 전처리
    - 5개 지역의 날씨 데이터를 로드하고, 택시 데이터와 조인할 수 있도록 날짜/시간 정보를 추출하며, 하나의 데이터프레임으로 통합
    - lit() function( Spark SQL 함수, 모든 행에 동일한 값을 가진 새로운 컬럼을 생성 ) → 각 날씨 데이터프레임에 borough 이름 추가 → 나중에 택시 데이터와 조인할 때 지역(borough) 기준으로 매칭하기 위해서
    - unionByName() → 두 Spark DataFrame을 합칠 때 사용 / union()과 달리, 컬럼의 순서가 달라도 컬럼 이름이 같으면 자동으로 매칭하여 합쳐줌 ( 한쪽에만 있는 컬럼은 다른 쪽에 null 값으로 채워짐 )
    - 결과적으로 df_weather에는 날짜/기온/강수량/자치구와 같은 형태로 만들어짐 → 이렇게 통합된 데이터프레임은 나중에 택시 데이터와 borough, date, time을 기준으로 조인할 때 사용됨

3. 택시 데이터와 날씨 데이터 조인
    - 시간별 상관관계를 분석하기 위한 핵심. 택시 이용 횟수 데이터와 날씨 데이터를 정확한 시간 단위로 매칭시킴
    - 조인 키 : borough, pickup_date, pickup_hour을  이용해서 inner join을 함 → 택시 데이터와 날씨 데이터의 지역-날짜-시간 조합이 같은 행만 포함 → Select를 통해 필요한 컬럼을 추가( trip_count, temperature, precipitation_amount )
    - 택시 데이터와 날씨 데이터가 합쳐짐
        
        → 최종 결과 컬럼 : Borough, pickup_date, pickup_hour, trip_count, temperature, precipitation_amount 
        
        → 지역, 날짜, 시간 단위로 택시 이용 횟수와 날씨 정보가 나란히 정리
        
4. 상관관계 분석
    - 최종 단계의 데이터프레임으로 각 지역별로 기온/강수량과 택시 이용 횟수 간의 상관관계를 계산
    - stat.corr()을 사용해 기온-택시 이용/강수량- 택시 이용에 대한 상관관계를 구함 ( 피어슨 상관관계 )

    - Correlation Results by Borough (Temperature vs. Trip Count, Precipitation vs. Trip Count)
    - Queens: Temperature Corr = 0.22, Precipitation Corr = 0.17
    - Brooklyn: Temperature Corr = 0.01, Precipitation Corr = -0.31
    - Staten Island: Temperature Corr = 0.85, Precipitation Corr = 0.27
    - Manhattan: Temperature Corr = -0.12, Precipitation Corr = 0.01
    - Bronx: Temperature Corr = 0.39, Precipitation Corr = 0.04

#### 인사이트 : 날씨가 택시 수요에 미치는 영향은 지역별로 상이함( 기온이 높을수록 택시 수요가 강하게 증가하는 지역, 강수량이 많을수록 택시 수요가 감소하는 지역, 날씨에 별로 영향을 안 받는 지역 등 기온과 강수량만으로는 택시 이용률과 관련해서 엄청 유의미한 인사이트를 도출할 수 없었음. 이것 이외에도 각종 인프라, 인구, 관광 지역, 계절, 특정 이벤트 등의 수많은 요인들을 고려해야 더 정확한 예측 모델을 만들 수 있을 거 같다는 생각을 했음

6. 지표 계산
    - 평균 이동 시간/ 거리 계산 : 2025년 5월 전체 택시 데이터를 기준으로 평균 이동 시간, 평균 이동 거리를 계산함

7. 피크 시간 분석
    - 시간대별 이용 횟수를 집계한 후 bar plot을 사용해 시각화

## 회고
  
### Keep
- 

### Problem
- W4M2 팀 활동 말고 과제에도 유스케이스를 쓰고 수행하라는 뉘앙스의 다노 강사님의 말을 못 본 채하고 주어진 요구사항에 대해서만 만족시켰음 -> 항상 유스케이스를 먼저 생각해봐야겠음

### Try
- 
