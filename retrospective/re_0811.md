## 리뷰
### 강의
- spark를 튜닝하는게 아니라 Job을 튜닝하는것이다
- data = Job 데이터를 모르고 optimizing을 한다는건 말이 안 됨 > 오늘 배우는 optimizing은 우리가 함
- the communication between nodes : spark 구조에서 제일 bottle neck임 > 그래서 shuffle을 어떻게 줄일지 혈안이다
- parquet를 쓰면 shuffle을 줄일 수 있다?
- push down
  - df.select(나이,성별).filter("age>20") >> 연산이 훨씬 크다. 
  - df.filter("age>20").select(나이,성별)
- Data Warehouse : 목적성을 갖는다
- Data Lake : 데이터를 일단 다 때려넣는다. 자주 쓰는 데이터는 structured, 로그 같은 데이터는 unstructured로 때려넣음
  - ELT가 그래서 나옴, 일단 저장해놓고 필요하면 Transform해서 씀
- Data Lakehouse : Cloud가 필요함
- network를 타는게 spark에서 제일 느린 bottle neck임
- repartitionByRange : 데이터를 보고 repartitioning 할 지를 결정해야된다. 예를 들면 서울역 일요일/ 금요일 승객이 다르니까 다르게 처리해야되듯이
- 스파크는 인메모리 툴이 아니다. LRU를 가진
- 캐시는 메모리에 들어가고, persist는 메모리나 디스크에 저장
- cache, persist, checkpoint(리니지를 갖고있는 RDD가 아니다)
- persist & checkpoint를 같이 쓰면 cache는 그 DAG안에서 두 번 세 번 쓰일때 사용, checkpoint는 다른 spark Job에서 다시 사용할 수 있으니까 같이 사용
- 결국 우리는 데이터를 보고 DAG를 개선하는 일이다.

### 최종 프로젝트 아이디어 구체화

- 우리의 데이터 프로덕트 사용자 여정을 짜봤습니다 ( 사용자가 견적서 평가를 보고 해당 정비소에서 수리를 받을 지 말 지 선택, 견적서 비교를 할 지 말 지도 사용자 마음이다. )
  1. 정비소 A를 들려서 견적을 내고 우리 프로덕트에 견적서를 넣어서 견적 평가를 받았음, 근데 과잉정비가 떴다 이 상황에서 다른 정비소를 추천하는 기능을 추가(거리, 리뷰데이터를 통해 가격이나 평점, 공업사 등급 등)
  
  2. 프로덕트 사용자가 정비소 B를 들렸는데 또 과잉정비가 떴음, 이럴때 1번과 같은 프로세스를 진행함
  
  3. 다음으로 정비소 C를 들렸더니 어중간한 케이스가 떴다, 이때도 다른 정비소를 똑같은 방법으로 추천해줌, 여기서 사용자는 정비소 C에서 그냥 받을지, 다른 정비소를 또 들릴지 결정. 정비소 C에서 받으면 끝인거고, 만약 다른 정비소를 가기로 결정했다고 쳤을때 4번으로 넘어감
  
  4. 정비소 D를 들렸더니 어중간한 케이스나 걱정이 사라지는 케이스가 떴어. 이때도 다른 프로세스랑 똑같이 추천 정비소는 디폴트로 추천을 해줘, 근데 사용자가 걱정이 사라지는 케이스에서 정비를 받을 수도 있는거고, 다른 견적이랑 비교를 받을 수도 있어. 이건 사용자 마음이야. 근데 만약, 이번에도 마음에 안 들어서 조금이라도 더 깍고 싶은 마음이 생겨서 다른 정비소를 들렸어. 그럼 총 5번 견적 평가를 받았으니 여기서 끝. 우리 서비스는 5만원을 내면 최대 5번 견적 평가를 받을 수 있게 제한을 걸었음 > 마음에 안 든다고 무제한으로 견적을 받게 할 순 없기 때문에.


## 회고
### Keep
- 

### Problem
-

### Try
-
