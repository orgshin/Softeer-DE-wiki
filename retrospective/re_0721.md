## 리뷰

## 강의
- Hadoop에 대해 이해하기 ( 이번주, 다음주 내용은 구식 / 하둡, 스파크가 왜 생겼는지 이해하기 )
- Cloud <> on-premise ( 클라우드랑 반대로 모든 시스템과 데이터를 자체적으로 관리하고 통제 )
- 데이터가 너무 많아져서 데이터베이스에 담을 수가 없어짐 > Scale Up을 하자니 돈이 너무 많이 듬 > 어떻게 하면 싸게 데이터를 저장할 수 있을까 고민함 > 데이터를 분산해서 저장하는 HDFS가 나옴

## Hadoop
- HDFS (저장) > Yarn(관리) > MapReduce(처리)
- Application Layer : MapReduce, Spark, Storm, Hive 필요에 따라 바꿔쓰면 됨
- abstract > interface가 필요함
- WORM의 장점 : 인덱싱 하기 편하다, 수정(Update)을 하지 않기 때문에 락을 걸지 않아도 된다(비용을 극단적으로 낮춤) > enables high throughout data access
- NameNode : 파일시스템의 metadata를 저장함, 깨지면 망하기 때문에 secondary NameNode를 준비해놓는다. 클라이언트랑 소통하면서 데이터가 어디있는지 알려주는 역할
- DataNode : 실제 데이터가 저장이 되지만 데이터의 정보에 대해서는 모름, NameNode의 metadata의 정보를 가지고 어디에 저장된 데이터를 달라고 클라이언트가 요청하면 데이터노드는 그 데이터를 꺼내주는 역할만 함, permission 같은 생각해야되는거는 다 NameNode가 해줌 >> 부하가 극단적으로 작아짐, 하는 일이 없음 바보임
- Data Locality : Rack(같은 허브에 묶여있다) locality 자기들끼리의 통신은 빠름 / 복제된 다른 노드에 있는 같은 데이터를 가져다 쓰면 오래걸리고 비용이 더 들기 때문에 Rack이라는 개념이 만들어짐
- Yarn(진짜 중요한 개념) : ResourceManager(resource management) <> ApplicationMaster(job scheduling/monitoring) 완전히 서로 떨어져 있음, 서로 관심이 없다 >> 비용을 낮추는 설계
- Resourcemanager는 app master만들고 app master가 resourcemager한테 어떤 일을 해야돼라고 요청하면 container(이 자원을) 쓰라고 지정해줌
- 데이터가 많아지면 많아질수록 저장비용은 늘어나지만 data locality가 높아지기 때문에 처리속도가 빨라지는 개념( 데이터가 많아지면 같은 노드에 데이터가 있을 가능성이 높아지기 때문 )


## 회고
  
### Keep


### Problem


### Try

