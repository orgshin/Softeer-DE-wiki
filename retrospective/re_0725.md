## 리뷰
  
## 오늘 한 일

### MapReduce Job 정리
- 빅 데이터가 들어와 hdfs에 저장을 했다 > 대용량 파일을 여러 개의 작은 블록 단위로 나누어 Hadoop Cluster 내의 여러 DataNode에 분산하여 저장 > 이때 각 블록은 데이터 유실 방지를 위해 여러 개의 복제본을 만들어 다른 노드에 분산 저장( 스케줄러는 복제본을 알고 있는 상태 ) > 블록들을 기반으로 입력 스플릿이 생성 > 각 입력 스플릿에 대해 하나의 Map task 할당 > DataNode에서 map task 실행 > 태스크 완료 후 그 결과인 중간 데이터를 자신이 실행된 노드의 로컬 디스크에 기록함
- 작은 블록 단위로 나누고 Split을 하는데 일반적으로 블록 사이즈와 Split하는 사이즈가 거의 비슷하다고 함. 처음에는 블록 단위로 나누는게 Split인 줄 알았다.

- Data Locality에 대해 잘 이해가 되지 않았었는데 왜 그런가 했더니 하나의 Cluster 안에 하나의 가상 머신/컴퓨터가 있다고만 생각하니 Data Local / Rack Local / Different Rack에 대해 잘못 이해하고 있었다.
- Input Data가 너무 커서 Hadoop Cluster에 여러 개의 컴퓨터가 있다고 가정했을때 Resourcemanager, NameNode는 클러스터 전체에서 하나 혹은 백업용으로 하나 더 존재함 > 같은 컴퓨터든 다른 컴퓨터든 네트워크 통신으로 SlaveNode/WorkerNode를 관리함( 컴포넌트가 자기 위치를 인식하지 않아도 됨 그냥 네트워크로 통신하는걸로 통일함 )
- 이렇게 생각을 하니까 Data Local / Rack Local에 대해서도 이해하기 쉬웠음 / Different Rack이라는 건 같은 Hadoop Cluster 내에 존재하는 자신 이외의 컴퓨터를 의미하는 것.
- MapTask, ReduceTask는 모든 WorkerNode에 있지않음. 만약 자기 workerNode에 MapTask가 없다면 다른 노드의 MapTask를 써야하는데 이럴때를 Rack Local 이라고 한다. MapTask를 같은 WorkerNode에서 진행할때를 Data Local이라고 한다.

### 헷갈리는 부분
- MapTask, ReducerTask를 하면서 sort가 언제 일어나는지, sort&shuffle
  
### W3M3
- 

## 회고
  
### Keep
- 

### Problem


### Try


