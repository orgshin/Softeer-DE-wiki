## 리뷰

## 강의
- MapReduce는 똑같은 데이터를 계속 iterative하게 처리함
- RDD : Overcoming Redundancy and Lack of In-Memory Reuse in MapReduce
- 하둡은 fault tolerance를 replication으로 지원, 스파크는 lineage로 지원
- 하둡은 local disk에서 깨져도 다시 하면되니까 fault tolerance가 필요 x, 스파크는 In-memory가 깨지면 안 되기 때문에 fault tolerance를 보장해줘야된다 생각함 / In-memory를 반복 사용 >> 깨지면 안 되니까 lineage 사용
- lineage : 자식이 깨지면 그 부모를 찾아가고 부모가 깨지면 조부를 찾아가고, 이런식으로 Resilient함
- immutable을 왜 썼을까? 동일한 데이터를 많은 프로세스가 쓸 때 혼란 생길게 없어서
- 파티션 사이즈를 잘 결정하는게 중요함 > 불균등하게 배분될 수 있기 때문 > 전형적으로 스파크가 알아서 정해줌
- spark context : action이 불러질때 job이 생성됨, 그 전까지는 기록만 하고있음(DAG)

  
1. Action : 굴리는 순간 실행
2. Transformation : 바로 실행되지 않음
- Action과 Transformation을 구분하는건 RDD가 생겼는지의 여부

- Lazy Evaluation은 코드를 킵 해놨다가 Action하는 순간 타고 올라가면서 숙제를 실행 / 불필요한 계산을 optimize하게 관리해줌
- Transformation의 연결선이 lineage다

1. Narrow : Shuffle을 안 일으킴
2. Wide : Shuffle을 일으킴

- Stage : Task의 집합, serially하면 같은 파티션에 놓는다, 절대 쪼개지 않음
- Computation boundaries : shuffle이 끝날때까지 reduce가 불가능함, 경계선이 존재


## 회고
  
### Keep
- 

### Problem
-

### Try
- 
